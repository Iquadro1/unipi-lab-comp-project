{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb45e4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples loaded and sorted\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gudhi as gd\n",
    "import glob\n",
    "import sklearn.manifold as manifold\n",
    "\n",
    "# Create a list of tuples, each containing:\n",
    "# 1. A name identifying the sample size (e.g., '500')\n",
    "# 2. The corresponding point cloud loaded from a NumPy file\n",
    "samples = [\n",
    "    (filename.split('_')[-1].split('.')[0], np.load(filename))\n",
    "    for filename in glob.glob('dragon_vrip_sampled_*.npy')\n",
    "]\n",
    "\n",
    "# Sort samples by their numeric values (convert string names to integers for proper sorti\n",
    "samples.sort(key=lambda x: int(x[0]))\n",
    "print(\"Samples loaded and sorted\")\n",
    "\n",
    "l = len(samples)\n",
    "\n",
    "# Use Multidimensional Scaling (MDS) to visualize topological differences between samples\n",
    "# This will allow us to visualize the relationships between the samples based on their persistence intervals\n",
    "# MDS (Multidimensional Scaling) reduces high-dimensional distance matrices to 2D for visualization\n",
    "mds = manifold.MDS(\n",
    "    n_components=2,        # Reduce to 2 dimensions for plotting\n",
    "    max_iter=3000,         # Maximum iterations for convergence\n",
    "    eps=1e-9,             # Convergence tolerance\n",
    "    dissimilarity=\"precomputed\",  # Use precomputed distance matrices B0, B1, B2\n",
    "    n_jobs=1,             # Number of parallel jobs\n",
    "    n_init=1              # Number of initializations (silences warnings)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b89201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store persistence intervals for each homological dimension\n",
    "# pl0: connected components (dimension 0)\n",
    "# pl1: loops/cycles (dimension 1) \n",
    "# pl2: voids/cavities (dimension 2)\n",
    "pl0 = []\n",
    "pl1 = []\n",
    "pl2 = []\n",
    "\n",
    "# Process each sample to extract persistence intervals\n",
    "for name, points in samples:\n",
    "    # Create Alpha Complex from point cloud\n",
    "    ac = gd.AlphaComplex(points=points)\n",
    "    \n",
    "    # Build simplex tree for topological analysis\n",
    "    st = ac.create_simplex_tree()\n",
    "    \n",
    "    # Compute persistent homology\n",
    "    bc = st.persistence()\n",
    "    \n",
    "    # Extract persistence intervals for each dimension and store them\n",
    "    pl0.append(st.persistence_intervals_in_dimension(0))  # Connected components\n",
    "    pl1.append(st.persistence_intervals_in_dimension(1))  # Loops/cycles\n",
    "    pl2.append(st.persistence_intervals_in_dimension(2))  # Voids/cavities\n",
    "    \n",
    "    print(f\"Persistence intervals for {name} appended.\")\n",
    "\n",
    "# # Display the shape of persistence intervals for each sample and dimension\n",
    "# for i, name in enumerate([s[0] for s in samples]):\n",
    "#     print(f\"{name}: dim0={pl0[i].shape}, dim1={pl1[i].shape}, dim2={pl2[i].shape}\")\n",
    "\n",
    "# Initialize distance matrices for each homological dimension\n",
    "# B0: bottleneck distances for connected components (dimension 0)\n",
    "# B1: bottleneck distances for loops/cycles (dimension 1) \n",
    "# B2: bottleneck distances for voids/cavities (dimension 2)\n",
    "B0 = np.zeros((l, l))\n",
    "B1 = np.zeros((l, l))\n",
    "B2 = np.zeros((l, l))\n",
    "\n",
    "# Compute pairwise bottleneck distances between persistence intervals\n",
    "# Only compute upper triangle to avoid redundant calculations\n",
    "for i in range(l):\n",
    "    for j in range(i):\n",
    "        # Calculate bottleneck distance between persistence intervals of samples i and j\n",
    "        B0[i,j] = gd.bottleneck_distance(pl0[i], pl0[j])  # Dimension 0\n",
    "        B1[i,j] = gd.bottleneck_distance(pl1[i], pl1[j])  # Dimension 1\n",
    "        B2[i,j] = gd.bottleneck_distance(pl2[i], pl2[j])  # Dimension 2\n",
    "        print(f\"Bottleneck distances for {samples[i][0]} and {samples[j][0]} computed.\")\n",
    "\n",
    "# Make distance matrices symmetric by adding the transpose\n",
    "# This fills in the lower triangle with the same values as the upper triangle\n",
    "B0 = B0 + B0.transpose()\n",
    "B1 = B1 + B1.transpose()\n",
    "B2 = B2 + B2.transpose()\n",
    "\n",
    "# Apply MDS to each bottleneck distance matrix to get 2D coordinates\n",
    "X0 = mds.fit_transform(B0)  # 2D embedding for dimension 0 (connected components)\n",
    "X1 = mds.fit_transform(B1)  # 2D embedding for dimension 1 (loops/cycles)\n",
    "X2 = mds.fit_transform(B2)  # 2D embedding for dimension 2 (voids/cavities)\n",
    "\n",
    "# Create a single figure with 3 vertically stacked subplots\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "sample_names = [s[0] for s in samples]  # Extract sample names for labeling\n",
    "\n",
    "# Plot dimension 0 embedding (connected components)\n",
    "axes[0].scatter(X0[:, 0], X0[:, 1], c=range(l), cmap='viridis')\n",
    "for i, name in enumerate(sample_names):\n",
    "    # Add sample name labels with slight offset to avoid overlap with points\n",
    "    axes[0].annotate(name, (X0[i, 0], X0[i, 1]), \n",
    "                    xytext=(X0[i, 0] + 0.000001, X0[i, 1] + 0.000001))\n",
    "axes[0].set_title('Dimension 0 (Connected Components)')\n",
    "\n",
    "# Plot dimension 1 embedding (loops/cycles)\n",
    "axes[1].scatter(X1[:, 0], X1[:, 1], c=range(l), cmap='viridis')\n",
    "for i, name in enumerate(sample_names):\n",
    "    # Add sample name labels with slight offset\n",
    "    axes[1].annotate(name, (X1[i, 0], X1[i, 1]), \n",
    "                    xytext=(X1[i, 0] + 0.000001, X1[i, 1] + 0.000001))\n",
    "axes[1].set_title('Dimension 1 (Loops)')\n",
    "\n",
    "# Plot dimension 2 embedding (voids/cavities)\n",
    "axes[2].scatter(X2[:, 0], X2[:, 1], c=range(l), cmap='viridis')\n",
    "for i, name in enumerate(sample_names):\n",
    "    # Add sample name labels with slight offset\n",
    "    axes[2].annotate(name, (X2[i, 0], X2[i, 1]), \n",
    "                    xytext=(X2[i, 0] + 0.000001, X2[i, 1] + 0.000001))\n",
    "axes[2].set_title('Dimension 2 (Voids)')\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # Get sample names\n",
    "# sample_names = [s[0] for s in samples]\n",
    "\n",
    "# # Plot dimension 0 embedding\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.scatter(X0[:, 0], X0[:, 1], c=range(l), cmap='viridis')\n",
    "# for i, name in enumerate(sample_names):\n",
    "#     plt.annotate(name, (X0[i, 0], X0[i, 1]))\n",
    "# plt.title('Dimension 0 (Connected Components)')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Plot dimension 1 embedding\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.scatter(X1[:, 0], X1[:, 1], c=range(l), cmap='viridis')\n",
    "# for i, name in enumerate(sample_names):\n",
    "#     plt.annotate(name, (X1[i, 0], X1[i, 1]))\n",
    "# plt.title('Dimension 1 (Loops)')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Plot dimension 2 embedding\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.scatter(X2[:, 0], X2[:, 1], c=range(l), cmap='viridis')\n",
    "# for i, name in enumerate(sample_names):\n",
    "#     plt.annotate(name, (X2[i, 0], X2[i, 1]))\n",
    "# plt.title('Dimension 2 (Voids)')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c44d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store persistence intervals for each homological dimension\n",
    "# pl0: connected components (dimension 0)\n",
    "# pl1: loops/cycles (dimension 1) \n",
    "# pl2: voids/cavities (dimension 2)\n",
    "pl0 = []\n",
    "pl1 = []\n",
    "pl2 = []\n",
    "\n",
    "# Process each sample to extract persistence intervals\n",
    "for name, points in samples:\n",
    "    # Create Alpha Complex from point cloud\n",
    "    ac = gd.DelaunayCechComplex(points=points)\n",
    "    \n",
    "    # Build simplex tree for topological analysis\n",
    "    st = ac.create_simplex_tree()\n",
    "    \n",
    "    # Compute persistent homology\n",
    "    bc = st.persistence()\n",
    "    \n",
    "    # Extract persistence intervals for each dimension and store them\n",
    "    pl0.append(st.persistence_intervals_in_dimension(0))  # Connected components\n",
    "    pl1.append(st.persistence_intervals_in_dimension(1))  # Loops/cycles\n",
    "    pl2.append(st.persistence_intervals_in_dimension(2))  # Voids/cavities\n",
    "    \n",
    "    print(f\"Persistence intervals for {name} appended.\")\n",
    "\n",
    "# # Display the shape of persistence intervals for each sample and dimension\n",
    "# for i, name in enumerate([s[0] for s in samples]):\n",
    "#     print(f\"{name}: dim0={pl0[i].shape}, dim1={pl1[i].shape}, dim2={pl2[i].shape}\")\n",
    "\n",
    "# Initialize distance matrices for each homological dimension\n",
    "# B0: bottleneck distances for connected components (dimension 0)\n",
    "# B1: bottleneck distances for loops/cycles (dimension 1) \n",
    "# B2: bottleneck distances for voids/cavities (dimension 2)\n",
    "B0 = np.zeros((l, l))\n",
    "B1 = np.zeros((l, l))\n",
    "B2 = np.zeros((l, l))\n",
    "\n",
    "# Compute pairwise bottleneck distances between persistence intervals\n",
    "# Only compute upper triangle to avoid redundant calculations\n",
    "for i in range(l):\n",
    "    for j in range(i):\n",
    "        # Calculate bottleneck distance between persistence intervals of samples i and j\n",
    "        B0[i,j] = gd.bottleneck_distance(pl0[i], pl0[j])  # Dimension 0\n",
    "        B1[i,j] = gd.bottleneck_distance(pl1[i], pl1[j])  # Dimension 1\n",
    "        B2[i,j] = gd.bottleneck_distance(pl2[i], pl2[j])  # Dimension 2\n",
    "        print(f\"Bottleneck distances for {samples[i][0]} and {samples[j][0]} computed.\")\n",
    "\n",
    "# Make distance matrices symmetric by adding the transpose\n",
    "# This fills in the lower triangle with the same values as the upper triangle\n",
    "B0 = B0 + B0.transpose()\n",
    "B1 = B1 + B1.transpose()\n",
    "B2 = B2 + B2.transpose()\n",
    "\n",
    "# Apply MDS to each bottleneck distance matrix to get 2D coordinates\n",
    "X0 = mds.fit_transform(B0)  # 2D embedding for dimension 0 (connected components)\n",
    "X1 = mds.fit_transform(B1)  # 2D embedding for dimension 1 (loops/cycles)\n",
    "X2 = mds.fit_transform(B2)  # 2D embedding for dimension 2 (voids/cavities)\n",
    "\n",
    "# Create a single figure with 3 vertically stacked subplots\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "sample_names = [s[0] for s in samples]  # Extract sample names for labeling\n",
    "\n",
    "# Plot dimension 0 embedding (connected components)\n",
    "axes[0].scatter(X0[:, 0], X0[:, 1], c=range(l), cmap='viridis')\n",
    "for i, name in enumerate(sample_names):\n",
    "    # Add sample name labels with slight offset to avoid overlap with points\n",
    "    axes[0].annotate(name, (X0[i, 0], X0[i, 1]), \n",
    "                    xytext=(X0[i, 0] + 0.000001, X0[i, 1] + 0.000001))\n",
    "axes[0].set_title('Dimension 0 (Connected Components)')\n",
    "\n",
    "# Plot dimension 1 embedding (loops/cycles)\n",
    "axes[1].scatter(X1[:, 0], X1[:, 1], c=range(l), cmap='viridis')\n",
    "for i, name in enumerate(sample_names):\n",
    "    # Add sample name labels with slight offset\n",
    "    axes[1].annotate(name, (X1[i, 0], X1[i, 1]), \n",
    "                    xytext=(X1[i, 0] + 0.000001, X1[i, 1] + 0.000001))\n",
    "axes[1].set_title('Dimension 1 (Loops)')\n",
    "\n",
    "# Plot dimension 2 embedding (voids/cavities)\n",
    "axes[2].scatter(X2[:, 0], X2[:, 1], c=range(l), cmap='viridis')\n",
    "for i, name in enumerate(sample_names):\n",
    "    # Add sample name labels with slight offset\n",
    "    axes[2].annotate(name, (X2[i, 0], X2[i, 1]), \n",
    "                    xytext=(X2[i, 0] + 0.000001, X2[i, 1] + 0.000001))\n",
    "axes[2].set_title('Dimension 2 (Voids)')\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63280ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing sample: 500\n",
      "Total points loaded: 500\n",
      "Number of landmark points chosen: 100\n",
      "Estimated data range: 0.26182231\n",
      "Using max_alpha_value: 0.00068551\n",
      "\n",
      "--- Euclidean Witness Complex Information ---\n",
      "Successfully created a Euclidean Witness Complex.\n",
      "Number of simplices in the complex: 5950\n",
      "Dimension of the complex: 2\n",
      "\n",
      "Computing persistent homology...\n",
      "Number of persistence pairs: 3818\n",
      "Persistence intervals for 500 appended.\n",
      "\n",
      "Processing sample: 750\n",
      "Total points loaded: 750\n",
      "Number of landmark points chosen: 150\n",
      "Estimated data range: 0.26079845\n",
      "Using max_alpha_value: 0.00068016\n",
      "\n",
      "--- Euclidean Witness Complex Information ---\n",
      "Successfully created a Euclidean Witness Complex.\n",
      "Number of simplices in the complex: 16758\n",
      "Dimension of the complex: 2\n",
      "\n",
      "Computing persistent homology...\n",
      "Number of persistence pairs: 12243\n",
      "Persistence intervals for 750 appended.\n",
      "\n",
      "Processing sample: 1000\n",
      "Total points loaded: 1000\n",
      "Number of landmark points chosen: 200\n",
      "Estimated data range: 0.25888351\n",
      "Using max_alpha_value: 0.00067021\n",
      "\n",
      "--- Euclidean Witness Complex Information ---\n",
      "Successfully created a Euclidean Witness Complex.\n",
      "Number of simplices in the complex: 36703\n",
      "Dimension of the complex: 2\n",
      "\n",
      "Computing persistent homology...\n",
      "Number of persistence pairs: 29086\n",
      "Persistence intervals for 1000 appended.\n",
      "\n",
      "Processing sample: 1250\n",
      "Total points loaded: 1250\n",
      "Number of landmark points chosen: 250\n",
      "Estimated data range: 0.26086947\n",
      "Using max_alpha_value: 0.00068053\n",
      "\n",
      "--- Euclidean Witness Complex Information ---\n",
      "Successfully created a Euclidean Witness Complex.\n",
      "Number of simplices in the complex: 78229\n",
      "Dimension of the complex: 2\n",
      "\n",
      "Computing persistent homology...\n",
      "Number of persistence pairs: 65348\n",
      "Persistence intervals for 1250 appended.\n",
      "\n",
      "Processing sample: 1500\n",
      "Total points loaded: 1500\n",
      "Number of landmark points chosen: 300\n",
      "Estimated data range: 0.26257294\n",
      "Using max_alpha_value: 0.00068945\n",
      "\n",
      "--- Euclidean Witness Complex Information ---\n",
      "Successfully created a Euclidean Witness Complex.\n",
      "Number of simplices in the complex: 141069\n",
      "Dimension of the complex: 2\n",
      "\n",
      "Computing persistent homology...\n",
      "Number of persistence pairs: 122185\n",
      "Persistence intervals for 1500 appended.\n",
      "\n",
      "Processing sample: 1750\n",
      "Total points loaded: 1750\n",
      "Number of landmark points chosen: 350\n",
      "Estimated data range: 0.26334834\n",
      "Using max_alpha_value: 0.00069352\n",
      "\n",
      "--- Euclidean Witness Complex Information ---\n",
      "Successfully created a Euclidean Witness Complex.\n",
      "Number of simplices in the complex: 190511\n",
      "Dimension of the complex: 2\n",
      "\n",
      "Computing persistent homology...\n",
      "Number of persistence pairs: 166213\n",
      "Persistence intervals for 1750 appended.\n",
      "\n",
      "Processing sample: 2000\n",
      "Total points loaded: 2000\n",
      "Number of landmark points chosen: 400\n",
      "Estimated data range: 0.26439834\n",
      "Using max_alpha_value: 0.00069906\n",
      "\n",
      "--- Euclidean Witness Complex Information ---\n",
      "Successfully created a Euclidean Witness Complex.\n",
      "Number of simplices in the complex: 296776\n",
      "Dimension of the complex: 2\n",
      "\n",
      "Computing persistent homology...\n",
      "Number of persistence pairs: 265041\n",
      "Persistence intervals for 2000 appended.\n",
      "\n",
      "Processing sample: 2250\n",
      "Total points loaded: 2250\n",
      "Number of landmark points chosen: 450\n",
      "Estimated data range: 0.26429346\n",
      "Using max_alpha_value: 0.00069851\n",
      "\n",
      "--- Euclidean Witness Complex Information ---\n",
      "Successfully created a Euclidean Witness Complex.\n",
      "Number of simplices in the complex: 451369\n",
      "Dimension of the complex: 2\n",
      "\n",
      "Computing persistent homology...\n",
      "Number of persistence pairs: 409066\n",
      "Persistence intervals for 2250 appended.\n",
      "\n",
      "Processing sample: 2500\n",
      "Total points loaded: 2500\n",
      "Number of landmark points chosen: 500\n",
      "Estimated data range: 0.26013038\n",
      "Using max_alpha_value: 0.00067668\n",
      "\n",
      "--- Euclidean Witness Complex Information ---\n",
      "Successfully created a Euclidean Witness Complex.\n",
      "Number of simplices in the complex: 538139\n",
      "Dimension of the complex: 2\n",
      "\n",
      "Computing persistent homology...\n",
      "Number of persistence pairs: 489067\n",
      "Persistence intervals for 2500 appended.\n",
      "\n",
      "Processing sample: 2750\n",
      "Total points loaded: 2750\n",
      "Number of landmark points chosen: 500\n",
      "Estimated data range: 0.26287574\n",
      "Using max_alpha_value: 0.00069104\n",
      "\n",
      "--- Euclidean Witness Complex Information ---\n",
      "Successfully created a Euclidean Witness Complex.\n",
      "Number of simplices in the complex: 517987\n",
      "Dimension of the complex: 2\n",
      "\n",
      "Computing persistent homology...\n",
      "Number of persistence pairs: 469908\n",
      "Persistence intervals for 2750 appended.\n",
      "\n",
      "Processing sample: 3000\n",
      "Total points loaded: 3000\n",
      "Number of landmark points chosen: 500\n",
      "Estimated data range: 0.26379517\n",
      "Using max_alpha_value: 0.00069588\n",
      "\n",
      "--- Euclidean Witness Complex Information ---\n",
      "Successfully created a Euclidean Witness Complex.\n",
      "Number of simplices in the complex: 608264\n",
      "Dimension of the complex: 2\n",
      "\n",
      "Computing persistent homology...\n",
      "Number of persistence pairs: 555811\n",
      "Persistence intervals for 3000 appended.\n",
      "\n",
      "Processing sample: 3250\n",
      "Total points loaded: 3250\n",
      "Number of landmark points chosen: 500\n",
      "Estimated data range: 0.26589373\n",
      "Using max_alpha_value: 0.00070699\n",
      "\n",
      "--- Euclidean Witness Complex Information ---\n",
      "Successfully created a Euclidean Witness Complex.\n",
      "Number of simplices in the complex: 612922\n",
      "Dimension of the complex: 2\n",
      "\n",
      "Computing persistent homology...\n",
      "Number of persistence pairs: 560640\n",
      "Persistence intervals for 3250 appended.\n",
      "\n",
      "Processing sample: 3500\n",
      "Total points loaded: 3500\n",
      "Number of landmark points chosen: 500\n",
      "Estimated data range: 0.26226291\n",
      "Using max_alpha_value: 0.00068782\n",
      "\n",
      "--- Euclidean Witness Complex Information ---\n",
      "Successfully created a Euclidean Witness Complex.\n",
      "Number of simplices in the complex: 519587\n",
      "Dimension of the complex: 2\n",
      "\n",
      "Computing persistent homology...\n",
      "Number of persistence pairs: 470518\n",
      "Persistence intervals for 3500 appended.\n",
      "\n",
      "Processing sample: 3750\n",
      "Total points loaded: 3750\n",
      "Number of landmark points chosen: 500\n",
      "Estimated data range: 0.26565805\n",
      "Using max_alpha_value: 0.00070574\n",
      "\n",
      "--- Euclidean Witness Complex Information ---\n",
      "Successfully created a Euclidean Witness Complex.\n",
      "Number of simplices in the complex: 577718\n",
      "Dimension of the complex: 2\n",
      "\n",
      "Computing persistent homology...\n",
      "Number of persistence pairs: 526218\n",
      "Persistence intervals for 3750 appended.\n",
      "\n",
      "Processing sample: 4000\n",
      "Total points loaded: 4000\n",
      "Number of landmark points chosen: 500\n",
      "Estimated data range: 0.26365808\n",
      "Using max_alpha_value: 0.00069516\n",
      "\n",
      "--- Euclidean Witness Complex Information ---\n",
      "Successfully created a Euclidean Witness Complex.\n",
      "Number of simplices in the complex: 601450\n",
      "Dimension of the complex: 2\n",
      "\n",
      "Computing persistent homology...\n",
      "Number of persistence pairs: 550190\n",
      "Persistence intervals for 4000 appended.\n",
      "Bottleneck distances for 750 and 500 computed.\n",
      "Bottleneck distances for 1000 and 500 computed.\n",
      "Bottleneck distances for 1000 and 750 computed.\n",
      "Bottleneck distances for 1250 and 500 computed.\n",
      "Bottleneck distances for 1250 and 750 computed.\n",
      "Bottleneck distances for 1250 and 1000 computed.\n",
      "Bottleneck distances for 1500 and 500 computed.\n",
      "Bottleneck distances for 1500 and 750 computed.\n",
      "Bottleneck distances for 1500 and 1000 computed.\n",
      "Bottleneck distances for 1500 and 1250 computed.\n",
      "Bottleneck distances for 1750 and 500 computed.\n",
      "Bottleneck distances for 1750 and 750 computed.\n",
      "Bottleneck distances for 1750 and 1000 computed.\n",
      "Bottleneck distances for 1750 and 1250 computed.\n",
      "Bottleneck distances for 1750 and 1500 computed.\n",
      "Bottleneck distances for 2000 and 500 computed.\n",
      "Bottleneck distances for 2000 and 750 computed.\n",
      "Bottleneck distances for 2000 and 1000 computed.\n",
      "Bottleneck distances for 2000 and 1250 computed.\n",
      "Bottleneck distances for 2000 and 1500 computed.\n",
      "Bottleneck distances for 2000 and 1750 computed.\n",
      "Bottleneck distances for 2250 and 500 computed.\n",
      "Bottleneck distances for 2250 and 750 computed.\n",
      "Bottleneck distances for 2250 and 1000 computed.\n",
      "Bottleneck distances for 2250 and 1250 computed.\n",
      "Bottleneck distances for 2250 and 1500 computed.\n",
      "Bottleneck distances for 2250 and 1750 computed.\n",
      "Bottleneck distances for 2250 and 2000 computed.\n",
      "Bottleneck distances for 2500 and 500 computed.\n",
      "Bottleneck distances for 2500 and 750 computed.\n",
      "Bottleneck distances for 2500 and 1000 computed.\n",
      "Bottleneck distances for 2500 and 1250 computed.\n",
      "Bottleneck distances for 2500 and 1500 computed.\n",
      "Bottleneck distances for 2500 and 1750 computed.\n",
      "Bottleneck distances for 2500 and 2000 computed.\n",
      "Bottleneck distances for 2500 and 2250 computed.\n",
      "Bottleneck distances for 2750 and 500 computed.\n",
      "Bottleneck distances for 2750 and 750 computed.\n",
      "Bottleneck distances for 2750 and 1000 computed.\n",
      "Bottleneck distances for 2750 and 1250 computed.\n",
      "Bottleneck distances for 2750 and 1500 computed.\n",
      "Bottleneck distances for 2750 and 1750 computed.\n",
      "Bottleneck distances for 2750 and 2000 computed.\n",
      "Bottleneck distances for 2750 and 2250 computed.\n",
      "Bottleneck distances for 2750 and 2500 computed.\n",
      "Bottleneck distances for 3000 and 500 computed.\n",
      "Bottleneck distances for 3000 and 750 computed.\n",
      "Bottleneck distances for 3000 and 1000 computed.\n",
      "Bottleneck distances for 3000 and 1250 computed.\n",
      "Bottleneck distances for 3000 and 1500 computed.\n",
      "Bottleneck distances for 3000 and 1750 computed.\n",
      "Bottleneck distances for 3000 and 2000 computed.\n",
      "Bottleneck distances for 3000 and 2250 computed.\n",
      "Bottleneck distances for 3000 and 2500 computed.\n",
      "Bottleneck distances for 3000 and 2750 computed.\n",
      "Bottleneck distances for 3250 and 500 computed.\n",
      "Bottleneck distances for 3250 and 750 computed.\n",
      "Bottleneck distances for 3250 and 1000 computed.\n",
      "Bottleneck distances for 3250 and 1250 computed.\n",
      "Bottleneck distances for 3250 and 1500 computed.\n",
      "Bottleneck distances for 3250 and 1750 computed.\n",
      "Bottleneck distances for 3250 and 2000 computed.\n",
      "Bottleneck distances for 3250 and 2250 computed.\n",
      "Bottleneck distances for 3250 and 2500 computed.\n",
      "Bottleneck distances for 3250 and 2750 computed.\n",
      "Bottleneck distances for 3250 and 3000 computed.\n",
      "Bottleneck distances for 3500 and 500 computed.\n",
      "Bottleneck distances for 3500 and 750 computed.\n",
      "Bottleneck distances for 3500 and 1000 computed.\n",
      "Bottleneck distances for 3500 and 1250 computed.\n",
      "Bottleneck distances for 3500 and 1500 computed.\n",
      "Bottleneck distances for 3500 and 1750 computed.\n",
      "Bottleneck distances for 3500 and 2000 computed.\n",
      "Bottleneck distances for 3500 and 2250 computed.\n",
      "Bottleneck distances for 3500 and 2500 computed.\n",
      "Bottleneck distances for 3500 and 2750 computed.\n",
      "Bottleneck distances for 3500 and 3000 computed.\n",
      "Bottleneck distances for 3500 and 3250 computed.\n",
      "Bottleneck distances for 3750 and 500 computed.\n",
      "Bottleneck distances for 3750 and 750 computed.\n",
      "Bottleneck distances for 3750 and 1000 computed.\n",
      "Bottleneck distances for 3750 and 1250 computed.\n",
      "Bottleneck distances for 3750 and 1500 computed.\n",
      "Bottleneck distances for 3750 and 1750 computed.\n",
      "Bottleneck distances for 3750 and 2000 computed.\n",
      "Bottleneck distances for 3750 and 2250 computed.\n",
      "Bottleneck distances for 3750 and 2500 computed.\n",
      "Bottleneck distances for 3750 and 2750 computed.\n",
      "Bottleneck distances for 3750 and 3000 computed.\n",
      "Bottleneck distances for 3750 and 3250 computed.\n",
      "Bottleneck distances for 3750 and 3500 computed.\n",
      "Bottleneck distances for 4000 and 500 computed.\n",
      "Bottleneck distances for 4000 and 750 computed.\n",
      "Bottleneck distances for 4000 and 1000 computed.\n",
      "Bottleneck distances for 4000 and 1250 computed.\n",
      "Bottleneck distances for 4000 and 1500 computed.\n",
      "Bottleneck distances for 4000 and 1750 computed.\n",
      "Bottleneck distances for 4000 and 2000 computed.\n",
      "Bottleneck distances for 4000 and 2250 computed.\n",
      "Bottleneck distances for 4000 and 2500 computed.\n",
      "Bottleneck distances for 4000 and 2750 computed.\n",
      "Bottleneck distances for 4000 and 3000 computed.\n",
      "Bottleneck distances for 4000 and 3250 computed.\n",
      "Bottleneck distances for 4000 and 3500 computed.\n",
      "Bottleneck distances for 4000 and 3750 computed.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 105\u001b[0m\n\u001b[1;32m    103\u001b[0m X0 \u001b[38;5;241m=\u001b[39m mds\u001b[38;5;241m.\u001b[39mfit_transform(B0)  \u001b[38;5;66;03m# 2D embedding for dimension 0 (connected components)\u001b[39;00m\n\u001b[1;32m    104\u001b[0m X1 \u001b[38;5;241m=\u001b[39m mds\u001b[38;5;241m.\u001b[39mfit_transform(B1)  \u001b[38;5;66;03m# 2D embedding for dimension 1 (loops/cycles)\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m X2 \u001b[38;5;241m=\u001b[39m \u001b[43mmds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB2\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 2D embedding for dimension 2 (voids/cavities)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Create a single figure with 3 vertically stacked subplots\u001b[39;00m\n\u001b[1;32m    108\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m))\n",
      "File \u001b[0;32m~/Develop/LabComp/ve/lib/python3.10/site-packages/sklearn/base.py:1363\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1359\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1360\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1361\u001b[0m     )\n\u001b[1;32m   1362\u001b[0m ):\n\u001b[0;32m-> 1363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Develop/LabComp/ve/lib/python3.10/site-packages/sklearn/manifold/_mds.py:685\u001b[0m, in \u001b[0;36mMDS.fit_transform\u001b[0;34m(self, X, y, init)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_init\n\u001b[0;32m--> 685\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdissimilarity \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    687\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    688\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe MDS API has changed. ``fit`` now constructs a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dissimilarity matrix from data. To use a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    690\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdissimilarity matrix, set \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``dissimilarity=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m``.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    692\u001b[0m     )\n",
      "File \u001b[0;32m~/Develop/LabComp/ve/lib/python3.10/site-packages/sklearn/utils/validation.py:2954\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2952\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m-> 2954\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2955\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m   2956\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/Develop/LabComp/ve/lib/python3.10/site-packages/sklearn/utils/validation.py:1105\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1102\u001b[0m     )\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[0;32m-> 1105\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1114\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/Develop/LabComp/ve/lib/python3.10/site-packages/sklearn/utils/validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Develop/LabComp/ve/lib/python3.10/site-packages/sklearn/utils/validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     )\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Create lists to store persistence intervals for each homological dimension\n",
    "# pl0: connected components (dimension 0)\n",
    "# pl1: loops/cycles (dimension 1) \n",
    "# pl2: voids/cavities (dimension 2)\n",
    "pl0 = []\n",
    "pl1 = []\n",
    "pl2 = []\n",
    "\n",
    "for name, points in samples:\n",
    "    \n",
    "    print(f\"\\nProcessing sample: {name}\")\n",
    "\n",
    "    # 1. Define Witness Points\n",
    "    # The full set of data points will serve as witness points.\n",
    "    witness_points = points\n",
    "\n",
    "    # 2. Choose Landmark Points\n",
    "    # We need to select a subset of `witness_points` to be `landmark_points`.\n",
    "    # A common strategy is random sampling. The number of landmarks significantly affects the computational cost and the approximation quality of the complex.\n",
    "    # For example, we choose a maximum of 500 landmarks, or 20% of total points, whichever is smaller, to keep the complex manageable.\n",
    "    num_total_points = witness_points.shape[0]\n",
    "    target_num_landmarks = min(500, int(0.2 * num_total_points))\n",
    "\n",
    "    num_landmarks = max(1, target_num_landmarks)\n",
    "    print(f\"\\nTotal points loaded: {num_total_points}\")\n",
    "    print(f\"Number of landmark points chosen: {num_landmarks}\")\n",
    "\n",
    "    # Randomly select indices for landmark points without replacement\n",
    "    landmark_indices = np.random.choice(num_total_points, num_landmarks, replace=False)\n",
    "    landmark_points = witness_points[landmark_indices]\n",
    "\n",
    "    # 3. Create the Euclidean Witness Complex\n",
    "    # The `max_alpha_value` parameter acts as a maximum allowed \"radius\" for a simplex to be included in the complex.\n",
    "    # - If too small, the complex might be empty or very sparse.\n",
    "    # - If too large, it might be too dense and computationally expensive.\n",
    "    # A heuristic to estimate `max_alpha_value` is to consider a fraction of the data's overall range or diameter.\n",
    "    min_coords = np.min(witness_points, axis=0)\n",
    "    max_coords = np.max(witness_points, axis=0)\n",
    "    data_range = np.linalg.norm(max_coords - min_coords) # Diagonal length of bounding box\n",
    "    \n",
    "    # A common starting point: 5-15% of the data range\n",
    "    estimated_max_alpha_value = data_range * 0.1\n",
    "    \n",
    "    # Fallback for very small or zero range (e.g., all points identical)\n",
    "    if estimated_max_alpha_value < 1e-6:\n",
    "        estimated_max_alpha_value = 1.0 \n",
    "\n",
    "    max_alpha_value = estimated_max_alpha_value ** 2 # create_simplex_tree expects squared radius\n",
    "    print(f\"Estimated data range: {data_range:.8f}\")\n",
    "    print(f\"Using max_alpha_value: {max_alpha_value:.8f}\")\n",
    "    \n",
    "    witness_complex = gd.EuclideanWitnessComplex(\n",
    "        landmarks=landmark_points,\n",
    "        witnesses=witness_points\n",
    "    )\n",
    "\n",
    "    # 4. Create the Simplex Tree from the witness complex\n",
    "    simplex_tree = witness_complex.create_simplex_tree(max_alpha_square=max_alpha_value, limit_dimension=2)\n",
    "\n",
    "    print(\"\\n--- Euclidean Witness Complex Information ---\")\n",
    "    print(f\"Successfully created a Euclidean Witness Complex.\")\n",
    "    print(f\"Number of simplices in the complex: {simplex_tree.num_simplices()}\")\n",
    "    print(f\"Dimension of the complex: {simplex_tree.dimension()}\")\n",
    "\n",
    "    # 5. Compute persistent homology\n",
    "    print(\"\\nComputing persistent homology...\")\n",
    "    persistence = simplex_tree.persistence(persistence_dim_max=True)\n",
    "    print(f\"Number of persistence pairs: {len(persistence)}\")\n",
    "\n",
    "    # 6. Extract persistence intervals for each dimension and store them\n",
    "    pl0.append(simplex_tree.persistence_intervals_in_dimension(0))  # Connected components\n",
    "    pl1.append(simplex_tree.persistence_intervals_in_dimension(1))  # Loops/cycles\n",
    "    pl2.append(simplex_tree.persistence_intervals_in_dimension(2))  # Voids/cavities\n",
    "\n",
    "    print(f\"Persistence intervals for {name} appended.\")\n",
    "            \n",
    "\n",
    "# Initialize distance matrices for each homological dimension\n",
    "# B0: bottleneck distances for connected components (dimension 0)\n",
    "# B1: bottleneck distances for loops/cycles (dimension 1) \n",
    "# B2: bottleneck distances for voids/cavities (dimension 2)\n",
    "B0 = np.zeros((l, l))\n",
    "B1 = np.zeros((l, l))\n",
    "B2 = np.zeros((l, l))\n",
    "\n",
    "# Compute pairwise bottleneck distances between persistence intervals\n",
    "# Only compute upper triangle to avoid redundant calculations\n",
    "for i in range(l):\n",
    "    for j in range(i):\n",
    "        # Calculate bottleneck distance between persistence intervals of samples i and j\n",
    "        B0[i,j] = gd.bottleneck_distance(pl0[i], pl0[j])  # Dimension 0\n",
    "        B1[i,j] = gd.bottleneck_distance(pl1[i], pl1[j])  # Dimension 1\n",
    "        B2[i,j] = gd.bottleneck_distance(pl2[i], pl2[j])  # Dimension 2\n",
    "        print(f\"Bottleneck distances for {samples[i][0]} and {samples[j][0]} computed.\")\n",
    "\n",
    "# Make distance matrices symmetric by adding the transpose\n",
    "# This fills in the lower triangle with the same values as the upper triangle\n",
    "B0 = B0 + B0.transpose()\n",
    "B1 = B1 + B1.transpose()\n",
    "B2 = B2 + B2.transpose()\n",
    "\n",
    "# Apply MDS to each bottleneck distance matrix to get 2D coordinates\n",
    "X0 = mds.fit_transform(B0)  # 2D embedding for dimension 0 (connected components)\n",
    "X1 = mds.fit_transform(B1)  # 2D embedding for dimension 1 (loops/cycles)\n",
    "X2 = mds.fit_transform(B2)  # 2D embedding for dimension 2 (voids/cavities)\n",
    "\n",
    "# Create a single figure with 3 vertically stacked subplots\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "sample_names = [s[0] for s in samples]  # Extract sample names for labeling\n",
    "\n",
    "# Plot dimension 0 embedding (connected components)\n",
    "axes[0].scatter(X0[:, 0], X0[:, 1], c=range(l), cmap='viridis')\n",
    "for i, name in enumerate(sample_names):\n",
    "    # Add sample name labels with slight offset to avoid overlap with points\n",
    "    axes[0].annotate(name, (X0[i, 0], X0[i, 1]), \n",
    "                    xytext=(X0[i, 0] + 0.000001, X0[i, 1] + 0.000001))\n",
    "axes[0].set_title('Dimension 0 (Connected Components)')\n",
    "\n",
    "# Plot dimension 1 embedding (loops/cycles)\n",
    "axes[1].scatter(X1[:, 0], X1[:, 1], c=range(l), cmap='viridis')\n",
    "for i, name in enumerate(sample_names):\n",
    "    # Add sample name labels with slight offset\n",
    "    axes[1].annotate(name, (X1[i, 0], X1[i, 1]), \n",
    "                    xytext=(X1[i, 0] + 0.000001, X1[i, 1] + 0.000001))\n",
    "axes[1].set_title('Dimension 1 (Loops)')\n",
    "\n",
    "# Plot dimension 2 embedding (voids/cavities)\n",
    "axes[2].scatter(X2[:, 0], X2[:, 1], c=range(l), cmap='viridis')\n",
    "for i, name in enumerate(sample_names):\n",
    "    # Add sample name labels with slight offset\n",
    "    axes[2].annotate(name, (X2[i, 0], X2[i, 1]), \n",
    "                    xytext=(X2[i, 0] + 0.000001, X2[i, 1] + 0.000001))\n",
    "axes[2].set_title('Dimension 2 (Voids)')\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfb1947",
   "metadata": {},
   "source": [
    "# Potential Issues with the Witness Complex Implementation\n",
    "\n",
    "## Problem Analysis:\n",
    "\n",
    "The main issues in the current Witness Complex code are:\n",
    "\n",
    "### 1. **Missing Error Handling**\n",
    "- The code removed the `try-except` block that was protecting against failures\n",
    "- If the complex creation fails for any sample, the entire process crashes\n",
    "\n",
    "### 2. **Incomplete Persistence Lists**\n",
    "- If any sample fails to process, the persistence lists (pl0, pl1, pl2) will have different lengths\n",
    "- This causes errors when computing bottleneck distances later\n",
    "\n",
    "### 3. **Potential Parameter Issues**\n",
    "- `max_alpha_value` might still be too restrictive for some datasets\n",
    "- The witness complex might produce empty or very sparse results\n",
    "\n",
    "### 4. **Missing Validation**\n",
    "- No check if the complex actually contains meaningful simplices\n",
    "- No validation that persistence intervals were successfully computed\n",
    "\n",
    "## Solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4379153a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing sample: 500\n",
      "Total points: 500, Landmarks: 100\n",
      "Trying max_alpha_value: 0.00068551 (multiplier: 0.1)\n",
      "Success! Complex has 5925 simplices\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.1\n",
      "Trying max_alpha_value: 0.00274204 (multiplier: 0.2)\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.1\n",
      "Trying max_alpha_value: 0.00274204 (multiplier: 0.2)\n",
      "Success! Complex has 51690 simplices\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.2\n",
      "Trying max_alpha_value: 0.00616958 (multiplier: 0.3)\n",
      "Success! Complex has 51690 simplices\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.2\n",
      "Trying max_alpha_value: 0.00616958 (multiplier: 0.3)\n",
      "Success! Complex has 144364 simplices\n",
      "Success! Complex has 144364 simplices\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.3\n",
      "Trying max_alpha_value: 0.01713773 (multiplier: 0.5)\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.3\n",
      "Trying max_alpha_value: 0.01713773 (multiplier: 0.5)\n",
      "Success! Complex has 166750 simplices\n",
      "Success! Complex has 166750 simplices\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.5\n",
      " Failed to process sample 500 with all alpha values\n",
      "\n",
      "Processing sample: 750\n",
      "Total points: 750, Landmarks: 150\n",
      "Trying max_alpha_value: 0.00068016 (multiplier: 0.1)\n",
      "Success! Complex has 16171 simplices\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.1\n",
      "Trying max_alpha_value: 0.00272063 (multiplier: 0.2)\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.5\n",
      " Failed to process sample 500 with all alpha values\n",
      "\n",
      "Processing sample: 750\n",
      "Total points: 750, Landmarks: 150\n",
      "Trying max_alpha_value: 0.00068016 (multiplier: 0.1)\n",
      "Success! Complex has 16171 simplices\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.1\n",
      "Trying max_alpha_value: 0.00272063 (multiplier: 0.2)\n",
      "Success! Complex has 177360 simplices\n",
      "Success! Complex has 177360 simplices\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.2\n",
      "Trying max_alpha_value: 0.00612143 (multiplier: 0.3)\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.2\n",
      "Trying max_alpha_value: 0.00612143 (multiplier: 0.3)\n",
      "Success! Complex has 484826 simplices\n",
      "Success! Complex has 484826 simplices\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.3\n",
      "Trying max_alpha_value: 0.01700396 (multiplier: 0.5)\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.3\n",
      "Trying max_alpha_value: 0.01700396 (multiplier: 0.5)\n",
      "Success! Complex has 562625 simplices\n",
      "Success! Complex has 562625 simplices\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.5\n",
      " Failed to process sample 750 with all alpha values\n",
      "\n",
      "Processing sample: 1000\n",
      "Total points: 1000, Landmarks: 200\n",
      "Trying max_alpha_value: 0.00067021 (multiplier: 0.1)\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.5\n",
      " Failed to process sample 750 with all alpha values\n",
      "\n",
      "Processing sample: 1000\n",
      "Total points: 1000, Landmarks: 200\n",
      "Trying max_alpha_value: 0.00067021 (multiplier: 0.1)\n",
      "Success! Complex has 39191 simplices\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.1\n",
      "Trying max_alpha_value: 0.00268083 (multiplier: 0.2)\n",
      "Success! Complex has 39191 simplices\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.1\n",
      "Trying max_alpha_value: 0.00268083 (multiplier: 0.2)\n",
      "Success! Complex has 392322 simplices\n",
      "Success! Complex has 392322 simplices\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.2\n",
      "Trying max_alpha_value: 0.00603186 (multiplier: 0.3)\n",
      "  Warning: Dim0 contains infinite values\n",
      "  Warning: Dim2 contains infinite values\n",
      "Invalid intervals with multiplier 0.2\n",
      "Trying max_alpha_value: 0.00603186 (multiplier: 0.3)\n",
      "Success! Complex has 1102764 simplices\n",
      "Success! Complex has 1102764 simplices\n"
     ]
    }
   ],
   "source": [
    "# CORRECTED VERSION: Witness Complex with proper error handling and infinite distance handling\n",
    "# Create lists to store persistence intervals for each homological dimension\n",
    "pl0_witness = []\n",
    "pl1_witness = []\n",
    "pl2_witness = []\n",
    "successful_samples = []  # Track which samples were successfully processed\n",
    "\n",
    "for name, points in samples:\n",
    "    print(f\"\\nProcessing sample: {name}\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Define Witness Points\n",
    "        witness_points = points\n",
    "        \n",
    "        # 2. Choose Landmark Points\n",
    "        num_total_points = witness_points.shape[0]\n",
    "        target_num_landmarks = min(500, int(0.2 * num_total_points))\n",
    "        num_landmarks = max(1, target_num_landmarks)\n",
    "        \n",
    "        print(f\"Total points: {num_total_points}, Landmarks: {num_landmarks}\")\n",
    "        \n",
    "        # Randomly select landmark points\n",
    "        landmark_indices = np.random.choice(num_total_points, num_landmarks, replace=False)\n",
    "        landmark_points = witness_points[landmark_indices]\n",
    "        \n",
    "        # 3. Estimate max_alpha_value\n",
    "        min_coords = np.min(witness_points, axis=0)\n",
    "        max_coords = np.max(witness_points, axis=0)\n",
    "        data_range = np.linalg.norm(max_coords - min_coords)\n",
    "        \n",
    "        # Try multiple alpha values if the first one fails\n",
    "        alpha_multipliers = [0.1, 0.2, 0.3, 0.5]  # Different percentages of data range\n",
    "        \n",
    "        success = False\n",
    "        for multiplier in alpha_multipliers:\n",
    "            estimated_max_alpha_value = data_range * multiplier\n",
    "            if estimated_max_alpha_value < 1e-6:\n",
    "                estimated_max_alpha_value = 1.0\n",
    "                \n",
    "            max_alpha_value = estimated_max_alpha_value ** 2\n",
    "            print(f\"Trying max_alpha_value: {max_alpha_value:.8f} (multiplier: {multiplier})\")\n",
    "            \n",
    "            try:\n",
    "                # 4. Create Witness Complex\n",
    "                witness_complex = gd.EuclideanWitnessComplex(\n",
    "                    landmarks=landmark_points,\n",
    "                    witnesses=witness_points\n",
    "                )\n",
    "                \n",
    "                # 5. Create Simplex Tree\n",
    "                simplex_tree = witness_complex.create_simplex_tree(\n",
    "                    max_alpha_square=max_alpha_value, \n",
    "                    limit_dimension=2\n",
    "                )\n",
    "                \n",
    "                # 6. Check if complex is meaningful\n",
    "                num_simplices = simplex_tree.num_simplices()\n",
    "                if num_simplices > 0:\n",
    "                    print(f\"Success! Complex has {num_simplices} simplices\")\n",
    "                    \n",
    "                    # 7. Compute persistent homology\n",
    "                    persistence = simplex_tree.persistence(persistence_dim_max=True)\n",
    "                    \n",
    "                    # 8. Extract persistence intervals\n",
    "                    intervals_0 = simplex_tree.persistence_intervals_in_dimension(0)\n",
    "                    intervals_1 = simplex_tree.persistence_intervals_in_dimension(1)\n",
    "                    intervals_2 = simplex_tree.persistence_intervals_in_dimension(2)\n",
    "                    \n",
    "                    # Check if intervals are valid (not empty and finite)\n",
    "                    valid_intervals = True\n",
    "                    for intervals, dim_name in [(intervals_0, \"Dim0\"), (intervals_1, \"Dim1\"), (intervals_2, \"Dim2\")]:\n",
    "                        if intervals.shape[0] == 0:\n",
    "                            print(f\"  Warning: {dim_name} has no intervals\")\n",
    "                        elif not np.all(np.isfinite(intervals)):\n",
    "                            print(f\"  Warning: {dim_name} contains infinite values\")\n",
    "                            valid_intervals = False\n",
    "                    \n",
    "                    if valid_intervals:\n",
    "                        # Only add if we have valid intervals\n",
    "                        pl0_witness.append(intervals_0)\n",
    "                        pl1_witness.append(intervals_1)\n",
    "                        pl2_witness.append(intervals_2)\n",
    "                        successful_samples.append(name)\n",
    "                        \n",
    "                        print(f\" Sample {name} processed successfully\")\n",
    "                        print(f\"  Intervals - Dim0: {intervals_0.shape}, Dim1: {intervals_1.shape}, Dim2: {intervals_2.shape}\")\n",
    "                        success = True\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"Invalid intervals with multiplier {multiplier}\")\n",
    "                else:\n",
    "                    print(f\"Complex is empty with multiplier {multiplier}\")\n",
    "                    \n",
    "            except Exception as inner_e:\n",
    "                print(f\"Failed with multiplier {multiplier}: {inner_e}\")\n",
    "                continue\n",
    "        \n",
    "        if not success:\n",
    "            print(f\" Failed to process sample {name} with all alpha values\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\" Error processing sample {name}: {e}\")\n",
    "\n",
    "print(f\"\\nSummary: Successfully processed {len(successful_samples)} out of {len(samples)} samples\")\n",
    "print(f\"Successful samples: {successful_samples}\")\n",
    "\n",
    "# Only proceed if we have enough successful samples\n",
    "if len(successful_samples) >= 2:\n",
    "    print(\"Proceeding with analysis...\")\n",
    "    \n",
    "    # Update the sample count for successful samples only\n",
    "    l_witness = len(successful_samples)\n",
    "    \n",
    "    # Compute bottleneck distances only for successful samples\n",
    "    B0_witness = np.zeros((l_witness, l_witness))\n",
    "    B1_witness = np.zeros((l_witness, l_witness))\n",
    "    B2_witness = np.zeros((l_witness, l_witness))\n",
    "    \n",
    "    print(\"Computing bottleneck distances...\")\n",
    "    for i in range(l_witness):\n",
    "        for j in range(i):\n",
    "            try:\n",
    "                # Compute distances with error handling\n",
    "                dist_0 = gd.bottleneck_distance(pl0_witness[i], pl0_witness[j])\n",
    "                dist_1 = gd.bottleneck_distance(pl1_witness[i], pl1_witness[j])\n",
    "                dist_2 = gd.bottleneck_distance(pl2_witness[i], pl2_witness[j])\n",
    "                \n",
    "                # Check for infinite distances and replace with a large finite value\n",
    "                max_finite_distance = 1000.0  # Reasonable upper bound\n",
    "                \n",
    "                B0_witness[i,j] = min(dist_0, max_finite_distance) if np.isfinite(dist_0) else max_finite_distance\n",
    "                B1_witness[i,j] = min(dist_1, max_finite_distance) if np.isfinite(dist_1) else max_finite_distance\n",
    "                B2_witness[i,j] = min(dist_2, max_finite_distance) if np.isfinite(dist_2) else max_finite_distance\n",
    "                \n",
    "                print(f\"Distances {successful_samples[i]}-{successful_samples[j]}: {B0_witness[i,j]:.4f}, {B1_witness[i,j]:.4f}, {B2_witness[i,j]:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error computing distance between {successful_samples[i]} and {successful_samples[j]}: {e}\")\n",
    "                # Use maximum distance as fallback\n",
    "                B0_witness[i,j] = max_finite_distance\n",
    "                B1_witness[i,j] = max_finite_distance\n",
    "                B2_witness[i,j] = max_finite_distance\n",
    "    \n",
    "    # Make symmetric\n",
    "    B0_witness = B0_witness + B0_witness.transpose()\n",
    "    B1_witness = B1_witness + B1_witness.transpose()\n",
    "    B2_witness = B2_witness + B2_witness.transpose()\n",
    "    \n",
    "    # Verify matrices are finite before MDS\n",
    "    matrices = [(B0_witness, \"B0\"), (B1_witness, \"B1\"), (B2_witness, \"B2\")]\n",
    "    for matrix, name in matrices:\n",
    "        if not np.all(np.isfinite(matrix)):\n",
    "            print(f\"Warning: {name} contains non-finite values!\")\n",
    "            print(f\"  Min: {np.min(matrix)}, Max: {np.max(matrix)}\")\n",
    "            print(f\"  Infinite values: {np.sum(~np.isfinite(matrix))}\")\n",
    "    \n",
    "    # Apply MDS with error handling\n",
    "    print(\"Applying MDS...\")\n",
    "    try:\n",
    "        X0_witness = mds.fit_transform(B0_witness)\n",
    "        print(\" MDS successful for dimension 0\")\n",
    "    except Exception as e:\n",
    "        print(f\" MDS failed for dimension 0: {e}\")\n",
    "        X0_witness = np.random.randn(l_witness, 2)  # Fallback to random positions\n",
    "    \n",
    "    try:\n",
    "        X1_witness = mds.fit_transform(B1_witness)\n",
    "        print(\" MDS successful for dimension 1\")\n",
    "    except Exception as e:\n",
    "        print(f\" MDS failed for dimension 1: {e}\")\n",
    "        X1_witness = np.random.randn(l_witness, 2)  # Fallback to random positions\n",
    "    \n",
    "    try:\n",
    "        X2_witness = mds.fit_transform(B2_witness)\n",
    "        print(\" MDS successful for dimension 2\")\n",
    "    except Exception as e:\n",
    "        print(f\" MDS failed for dimension 2: {e}\")\n",
    "        X2_witness = np.random.randn(l_witness, 2)  # Fallback to random positions\n",
    "    \n",
    "    # Plot results\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "    \n",
    "    axes[0].scatter(X0_witness[:, 0], X0_witness[:, 1], c=range(l_witness), cmap='viridis')\n",
    "    for i, name in enumerate(successful_samples):\n",
    "        axes[0].annotate(name, (X0_witness[i, 0], X0_witness[i, 1]), \n",
    "                        xytext=(5, 5), textcoords='offset points')\n",
    "    axes[0].set_title('Witness Complex - Dimension 0 (Connected Components)')\n",
    "    \n",
    "    axes[1].scatter(X1_witness[:, 0], X1_witness[:, 1], c=range(l_witness), cmap='viridis')\n",
    "    for i, name in enumerate(successful_samples):\n",
    "        axes[1].annotate(name, (X1_witness[i, 0], X1_witness[i, 1]), \n",
    "                        xytext=(5, 5), textcoords='offset points')\n",
    "    axes[1].set_title('Witness Complex - Dimension 1 (Loops)')\n",
    "    \n",
    "    axes[2].scatter(X2_witness[:, 0], X2_witness[:, 1], c=range(l_witness), cmap='viridis')\n",
    "    for i, name in enumerate(successful_samples):\n",
    "        axes[2].annotate(name, (X2_witness[i, 0], X2_witness[i, 1]), \n",
    "                        xytext=(5, 5), textcoords='offset points')\n",
    "    axes[2].set_title('Witness Complex - Dimension 2 (Voids)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Not enough successful samples to proceed with analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
